{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Recognizing with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading, preparing and exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "y_train = train[\"label\"]\n",
    "x_train = train.drop(labels = [\"label\"], axis = 1)\n",
    "del train\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping for Keras\n",
    "x_train = x_train.values.reshape(-1, 28, 28, 1)\n",
    "test = test.values.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Normalizing the values\n",
    "x_train = x_train.astype(\"float\")\n",
    "test = test.astype(\"float\")\n",
    "x_train /= 255.0\n",
    "test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the labels categorical\n",
    "y_train = to_categorical(y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the training data into training and validation set\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of this image is:  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ac8ca17730>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking out one random image and its label\n",
    "print(\"The label of this image is: \", y_train[123])\n",
    "plt.imshow(x_train[123], cmap=\"Greys\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "I'll try and compare the performance of having two Conv2D layers and Pooling layers once, twice and three times with ascending filter numbers (see below).\n",
    "### Once the Conv2D layers and Pooling layer (32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding = \"Same\", activation = \"relu\", input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(32, kernel_size=(3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=30, validation_data = (x_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twice the Conv2D and Pooling layers (32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2triples = Sequential()\n",
    "model2triples.add(Conv2D(32, kernel_size=(3,3), padding = \"Same\", activation = \"relu\", input_shape=(28, 28, 1)))\n",
    "model2triples.add(Conv2D(32, kernel_size=(3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model2triples.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2triples.add(Dropout(0.4))\n",
    "\n",
    "model2triples.add(Conv2D(64, kernel_size=(3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model2triples.add(Conv2D(64, kernel_size=(3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model2triples.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model2triples.add(Dropout(0.4))\n",
    "\n",
    "model2triples.add(Flatten())\n",
    "model2triples.add(Dense(256, activation=\"relu\"))\n",
    "model2triples.add(Dropout(0.4))\n",
    "model2triples.add(Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1182/1182 [==============================] - 27s 22ms/step - loss: 0.2244 - accuracy: 0.9294 - val_loss: 0.0688 - val_accuracy: 0.9793\n",
      "Epoch 2/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0818 - accuracy: 0.9744 - val_loss: 0.0562 - val_accuracy: 0.9812\n",
      "Epoch 3/30\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0642 - accuracy: 0.9813 - val_loss: 0.0312 - val_accuracy: 0.9895\n",
      "Epoch 4/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0514 - accuracy: 0.9842 - val_loss: 0.0306 - val_accuracy: 0.9907\n",
      "Epoch 5/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0474 - accuracy: 0.9848 - val_loss: 0.0278 - val_accuracy: 0.9912\n",
      "Epoch 6/30\n",
      "1182/1182 [==============================] - 28s 24ms/step - loss: 0.0409 - accuracy: 0.9874 - val_loss: 0.0297 - val_accuracy: 0.9900\n",
      "Epoch 7/30\n",
      "1182/1182 [==============================] - 29s 24ms/step - loss: 0.0368 - accuracy: 0.9883 - val_loss: 0.0262 - val_accuracy: 0.9919\n",
      "Epoch 8/30\n",
      "1182/1182 [==============================] - 27s 23ms/step - loss: 0.0331 - accuracy: 0.9897 - val_loss: 0.0265 - val_accuracy: 0.9926\n",
      "Epoch 9/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0326 - accuracy: 0.9903 - val_loss: 0.0246 - val_accuracy: 0.9917\n",
      "Epoch 10/30\n",
      "1182/1182 [==============================] - 27s 23ms/step - loss: 0.0296 - accuracy: 0.9912 - val_loss: 0.0307 - val_accuracy: 0.9919\n",
      "Epoch 11/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0298 - accuracy: 0.9911 - val_loss: 0.0242 - val_accuracy: 0.9926\n",
      "Epoch 12/30\n",
      "1182/1182 [==============================] - 27s 22ms/step - loss: 0.0262 - accuracy: 0.9920 - val_loss: 0.0247 - val_accuracy: 0.9948\n",
      "Epoch 13/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 0.0245 - val_accuracy: 0.9914\n",
      "Epoch 14/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0242 - accuracy: 0.9924 - val_loss: 0.0274 - val_accuracy: 0.9931\n",
      "Epoch 15/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.0250 - val_accuracy: 0.9929\n",
      "Epoch 16/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0221 - accuracy: 0.9930 - val_loss: 0.0249 - val_accuracy: 0.9933\n",
      "Epoch 17/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0251 - accuracy: 0.9926 - val_loss: 0.0277 - val_accuracy: 0.9924\n",
      "Epoch 18/30\n",
      "1182/1182 [==============================] - 27s 23ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0244 - val_accuracy: 0.9929\n",
      "Epoch 19/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 0.0258 - val_accuracy: 0.9936\n",
      "Epoch 20/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0212 - accuracy: 0.9933 - val_loss: 0.0273 - val_accuracy: 0.9921\n",
      "Epoch 21/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0218 - accuracy: 0.9933 - val_loss: 0.0254 - val_accuracy: 0.9938\n",
      "Epoch 22/30\n",
      "1182/1182 [==============================] - 32s 27ms/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 0.0231 - val_accuracy: 0.9943\n",
      "Epoch 23/30\n",
      "1182/1182 [==============================] - 28s 23ms/step - loss: 0.0202 - accuracy: 0.9940 - val_loss: 0.0234 - val_accuracy: 0.9945\n",
      "Epoch 24/30\n",
      "1182/1182 [==============================] - 27s 23ms/step - loss: 0.0205 - accuracy: 0.9938 - val_loss: 0.0265 - val_accuracy: 0.9938\n",
      "Epoch 25/30\n",
      "1182/1182 [==============================] - 28s 23ms/step - loss: 0.0173 - accuracy: 0.9954 - val_loss: 0.0239 - val_accuracy: 0.9931\n",
      "Epoch 26/30\n",
      "1182/1182 [==============================] - 29s 24ms/step - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.0257 - val_accuracy: 0.9926\n",
      "Epoch 27/30\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.0290 - val_accuracy: 0.9929\n",
      "Epoch 28/30\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0252 - val_accuracy: 0.9931\n",
      "Epoch 29/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0314 - val_accuracy: 0.9926\n",
      "Epoch 30/30\n",
      "1182/1182 [==============================] - 27s 22ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0302 - val_accuracy: 0.9938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ac8816cdc0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2triples.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "model2triples.fit(x_train, y_train, epochs=30, validation_data = (x_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three times the Conv2D and Pooling layers (24, 48, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3triples = Sequential()\n",
    "model3triples.add(Conv2D(24, kernel_size=(3,3), padding = \"Same\", activation = \"relu\", input_shape=(28, 28, 1)))\n",
    "model3triples.add(Conv2D(64, kernel_size=(3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model3triples.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3triples.add(Dropout(0.4))\n",
    "\n",
    "model3triples.add(Conv2D(48, kernel_size=(3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model3triples.add(Conv2D(48, kernel_size=(3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model3triples.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3triples.add(Dropout(0.4))\n",
    "\n",
    "model3triples.add(Conv2D(64, kernel_size=(3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model3triples.add(Conv2D(64, kernel_size=(3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model3triples.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model3triples.add(Dropout(0.4))\n",
    "\n",
    "model3triples.add(Flatten())\n",
    "model3triples.add(Dense(256, activation=\"relu\"))\n",
    "model3triples.add(Dropout(0.4))\n",
    "model3triples.add(Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1182/1182 [==============================] - 42s 35ms/step - loss: 0.3419 - accuracy: 0.8884 - val_loss: 0.0593 - val_accuracy: 0.9848\n",
      "Epoch 2/30\n",
      "1182/1182 [==============================] - 39s 33ms/step - loss: 0.1015 - accuracy: 0.9701 - val_loss: 0.0464 - val_accuracy: 0.9879\n",
      "Epoch 3/30\n",
      "1182/1182 [==============================] - 40s 34ms/step - loss: 0.0783 - accuracy: 0.9764 - val_loss: 0.0371 - val_accuracy: 0.9902\n",
      "Epoch 4/30\n",
      "1182/1182 [==============================] - 41s 35ms/step - loss: 0.0672 - accuracy: 0.9797 - val_loss: 0.0385 - val_accuracy: 0.9883\n",
      "Epoch 5/30\n",
      "1182/1182 [==============================] - 41s 35ms/step - loss: 0.0612 - accuracy: 0.9818 - val_loss: 0.0324 - val_accuracy: 0.9898\n",
      "Epoch 6/30\n",
      "1182/1182 [==============================] - 40s 34ms/step - loss: 0.0540 - accuracy: 0.9836 - val_loss: 0.0322 - val_accuracy: 0.9910\n",
      "Epoch 7/30\n",
      "1182/1182 [==============================] - 40s 34ms/step - loss: 0.0511 - accuracy: 0.9849 - val_loss: 0.0339 - val_accuracy: 0.9905\n",
      "Epoch 8/30\n",
      "1182/1182 [==============================] - 39s 33ms/step - loss: 0.0492 - accuracy: 0.9853 - val_loss: 0.0312 - val_accuracy: 0.9900\n",
      "Epoch 9/30\n",
      "1182/1182 [==============================] - 39s 33ms/step - loss: 0.0468 - accuracy: 0.9866 - val_loss: 0.0336 - val_accuracy: 0.9898\n",
      "Epoch 10/30\n",
      "1182/1182 [==============================] - 39s 33ms/step - loss: 0.0453 - accuracy: 0.9868 - val_loss: 0.0352 - val_accuracy: 0.9902\n",
      "Epoch 11/30\n",
      "1182/1182 [==============================] - 39s 33ms/step - loss: 0.0423 - accuracy: 0.9878 - val_loss: 0.0302 - val_accuracy: 0.9912\n",
      "Epoch 12/30\n",
      "1182/1182 [==============================] - 40s 34ms/step - loss: 0.0414 - accuracy: 0.9881 - val_loss: 0.0287 - val_accuracy: 0.9907\n",
      "Epoch 13/30\n",
      "1182/1182 [==============================] - 41s 35ms/step - loss: 0.0429 - accuracy: 0.9875 - val_loss: 0.0253 - val_accuracy: 0.9931\n",
      "Epoch 14/30\n",
      "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0407 - accuracy: 0.9885 - val_loss: 0.0348 - val_accuracy: 0.9898\n",
      "Epoch 15/30\n",
      "1182/1182 [==============================] - 39s 33ms/step - loss: 0.0419 - accuracy: 0.9876 - val_loss: 0.0289 - val_accuracy: 0.9919\n",
      "Epoch 16/30\n",
      "1182/1182 [==============================] - 42s 35ms/step - loss: 0.0405 - accuracy: 0.9879 - val_loss: 0.0256 - val_accuracy: 0.9926\n",
      "Epoch 17/30\n",
      "1182/1182 [==============================] - 40s 34ms/step - loss: 0.0408 - accuracy: 0.9885 - val_loss: 0.0395 - val_accuracy: 0.9902\n",
      "Epoch 18/30\n",
      "1182/1182 [==============================] - 41s 35ms/step - loss: 0.0385 - accuracy: 0.9886 - val_loss: 0.0317 - val_accuracy: 0.9910\n",
      "Epoch 19/30\n",
      "1182/1182 [==============================] - 42s 36ms/step - loss: 0.0404 - accuracy: 0.9878 - val_loss: 0.0339 - val_accuracy: 0.9893\n",
      "Epoch 20/30\n",
      "1182/1182 [==============================] - 39s 33ms/step - loss: 0.0368 - accuracy: 0.9894 - val_loss: 0.0272 - val_accuracy: 0.9921\n",
      "Epoch 21/30\n",
      "1182/1182 [==============================] - 39s 33ms/step - loss: 0.0403 - accuracy: 0.9889 - val_loss: 0.0383 - val_accuracy: 0.9900\n",
      "Epoch 22/30\n",
      "1182/1182 [==============================] - 39s 33ms/step - loss: 0.0413 - accuracy: 0.9874 - val_loss: 0.0308 - val_accuracy: 0.9917\n",
      "Epoch 23/30\n",
      "1182/1182 [==============================] - 40s 34ms/step - loss: 0.0375 - accuracy: 0.9898 - val_loss: 0.0321 - val_accuracy: 0.9917\n",
      "Epoch 24/30\n",
      "1182/1182 [==============================] - 39s 33ms/step - loss: 0.0388 - accuracy: 0.9889 - val_loss: 0.0306 - val_accuracy: 0.9921\n",
      "Epoch 25/30\n",
      "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0370 - accuracy: 0.9895 - val_loss: 0.0420 - val_accuracy: 0.9914\n",
      "Epoch 26/30\n",
      "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0357 - accuracy: 0.9895 - val_loss: 0.0268 - val_accuracy: 0.9933\n",
      "Epoch 27/30\n",
      "1182/1182 [==============================] - 42s 36ms/step - loss: 0.0373 - accuracy: 0.9897 - val_loss: 0.0349 - val_accuracy: 0.9905\n",
      "Epoch 28/30\n",
      "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0367 - accuracy: 0.9894 - val_loss: 0.0323 - val_accuracy: 0.9926\n",
      "Epoch 29/30\n",
      "1182/1182 [==============================] - 40s 34ms/step - loss: 0.0367 - accuracy: 0.9895 - val_loss: 0.0331 - val_accuracy: 0.9917\n",
      "Epoch 30/30\n",
      "1182/1182 [==============================] - 40s 34ms/step - loss: 0.0335 - accuracy: 0.9901 - val_loss: 0.0277 - val_accuracy: 0.9931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ac8c741c90>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3triples.compile(optimizer=\"adam\", \n",
    "              loss=\"categorical_crossentropy\", \n",
    "              metrics=[\"accuracy\"])\n",
    "model3triples.fit(x_train, y_train, epochs=30, validation_data = (x_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 2s 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[401,   0,   3,   0,   0,   0,   3,   1,   0,   0],\n",
       "       [  0, 469,   1,   0,   0,   0,   0,   1,   0,   0],\n",
       "       [  0,   1, 413,   0,   3,   0,   0,   1,   1,   1],\n",
       "       [  0,   0,   1, 499,   0,   2,   0,   1,   3,   0],\n",
       "       [  0,   0,   0,   0, 386,   0,   2,   1,   0,   8],\n",
       "       [  0,   0,   1,   3,   0, 329,   1,   0,   1,   4],\n",
       "       [  2,   0,   1,   0,   0,   1, 396,   0,   2,   0],\n",
       "       [  0,   0,   4,   0,   0,   0,   0, 430,   0,   4],\n",
       "       [  1,   0,   2,   2,   1,   1,   0,   1, 395,   0],\n",
       "       [  0,   0,   1,   2,   0,   0,   0,   1,   2, 410]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_val)\n",
    "y_pred_classes = np.argmax(y_pred,axis = 1)\n",
    "y_true = np.argmax(y_val,axis = 1) \n",
    "confusion_matrix(y_true, y_pred_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running it on the test set and preparing the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the test set images\n",
    "results = model.predict(test)\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the dataframe into a csv file\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission.to_csv(\"./data/first_cnn.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a28cd90ab7370ee8139c294f0b491a85c59cce1746513959106cf97723da925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
