{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Recognizing with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading, preparing and exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "y_train = train[\"label\"]\n",
    "x_train = train.drop(labels = [\"label\"], axis = 1)\n",
    "del train\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in train set (x_train): False\n",
      "NaN values in label set (y_train): False\n",
      "NaN values in test set: False\n"
     ]
    }
   ],
   "source": [
    "# check if there are NaN values in the data sets\n",
    "print(\"NaN values in train set (x_train):\", x_train.isnull().values.any())\n",
    "print(\"NaN values in label set (y_train):\", y_train.isnull().values.any())\n",
    "print(\"NaN values in test set:\", test.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping for Keras\n",
    "x_train = x_train.values.reshape(-1, 28, 28, 1)\n",
    "test = test.values.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Normalizing the values\n",
    "x_train = x_train.astype(\"float\")\n",
    "test = test.astype(\"float\")\n",
    "x_train /= 255.0\n",
    "test /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the labels categorical\n",
    "y_train = to_categorical(y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the training data into training and validation set\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of this image is:  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b384305a80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking out one random image and its label\n",
    "print(\"The label of this image is: \", y_train[123])\n",
    "plt.imshow(x_train[123], cmap= \"Greys\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "I'll try and compare the performance of having two Conv2D layers and Pooling layers once, twice and three times with ascending filter numbers (see below). The other layers use values that performed the best in trials, but were not changed when comparing the three setups.\n",
    "### Once the Conv2D layers and Pooling layer (32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size = (3,3), padding = \"Same\", activation = \"relu\", input_shape = (28, 28, 1)))\n",
    "model.add(Conv2D(32, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1182/1182 [==============================] - 21s 17ms/step - loss: 0.1914 - accuracy: 0.9402 - val_loss: 0.0689 - val_accuracy: 0.9800\n",
      "Epoch 2/30\n",
      "1182/1182 [==============================] - 19s 16ms/step - loss: 0.0693 - accuracy: 0.9776 - val_loss: 0.0494 - val_accuracy: 0.9857\n",
      "Epoch 3/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0534 - accuracy: 0.9840 - val_loss: 0.0536 - val_accuracy: 0.9838\n",
      "Epoch 4/30\n",
      "1182/1182 [==============================] - 19s 16ms/step - loss: 0.0444 - accuracy: 0.9854 - val_loss: 0.0386 - val_accuracy: 0.9888\n",
      "Epoch 5/30\n",
      "1182/1182 [==============================] - 19s 16ms/step - loss: 0.0354 - accuracy: 0.9881 - val_loss: 0.0404 - val_accuracy: 0.9886\n",
      "Epoch 6/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0300 - accuracy: 0.9901 - val_loss: 0.0552 - val_accuracy: 0.9860\n",
      "Epoch 7/30\n",
      "1182/1182 [==============================] - 21s 18ms/step - loss: 0.0276 - accuracy: 0.9907 - val_loss: 0.0398 - val_accuracy: 0.9898\n",
      "Epoch 8/30\n",
      "1182/1182 [==============================] - 19s 16ms/step - loss: 0.0249 - accuracy: 0.9917 - val_loss: 0.0468 - val_accuracy: 0.9898\n",
      "Epoch 9/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.0438 - val_accuracy: 0.9886\n",
      "Epoch 10/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.0371 - val_accuracy: 0.9898\n",
      "Epoch 11/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0182 - accuracy: 0.9942 - val_loss: 0.0402 - val_accuracy: 0.9907\n",
      "Epoch 12/30\n",
      "1182/1182 [==============================] - 19s 16ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.0343 - val_accuracy: 0.9902\n",
      "Epoch 13/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0154 - accuracy: 0.9949 - val_loss: 0.0369 - val_accuracy: 0.9905\n",
      "Epoch 14/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0374 - val_accuracy: 0.9912\n",
      "Epoch 15/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0429 - val_accuracy: 0.9905\n",
      "Epoch 16/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0142 - accuracy: 0.9950 - val_loss: 0.0469 - val_accuracy: 0.9905\n",
      "Epoch 17/30\n",
      "1182/1182 [==============================] - 19s 16ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.0379 - val_accuracy: 0.9907\n",
      "Epoch 18/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0459 - val_accuracy: 0.9902\n",
      "Epoch 19/30\n",
      "1182/1182 [==============================] - 21s 17ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.0370 - val_accuracy: 0.9914\n",
      "Epoch 20/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0360 - val_accuracy: 0.9926\n",
      "Epoch 21/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0116 - accuracy: 0.9961 - val_loss: 0.0484 - val_accuracy: 0.9919\n",
      "Epoch 22/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0347 - val_accuracy: 0.9926\n",
      "Epoch 23/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0492 - val_accuracy: 0.9912\n",
      "Epoch 24/30\n",
      "1182/1182 [==============================] - 19s 16ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0556 - val_accuracy: 0.9917\n",
      "Epoch 25/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0396 - val_accuracy: 0.9924\n",
      "Epoch 26/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.0383 - val_accuracy: 0.9919\n",
      "Epoch 27/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0369 - val_accuracy: 0.9926\n",
      "Epoch 28/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0348 - val_accuracy: 0.9929\n",
      "Epoch 29/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0342 - val_accuracy: 0.9931\n",
      "Epoch 30/30\n",
      "1182/1182 [==============================] - 20s 17ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0333 - val_accuracy: 0.9919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b384959a50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", \n",
    "              metrics = [\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs = 30, validation_data = (x_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twice the Conv2D and Pooling layers (32, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2triples = Sequential()\n",
    "model2triples.add(Conv2D(32, kernel_size = (3,3), padding = \"Same\", activation = \"relu\", input_shape = (28, 28, 1)))\n",
    "model2triples.add(Conv2D(32, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model2triples.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model2triples.add(Dropout(0.4))\n",
    "\n",
    "model2triples.add(Conv2D(64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model2triples.add(Conv2D(64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model2triples.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model2triples.add(Dropout(0.4))\n",
    "\n",
    "model2triples.add(Flatten())\n",
    "model2triples.add(Dense(256, activation = \"relu\"))\n",
    "model2triples.add(Dropout(0.4))\n",
    "model2triples.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1182/1182 [==============================] - 36s 30ms/step - loss: 0.2203 - accuracy: 0.9298 - val_loss: 0.0561 - val_accuracy: 0.9831\n",
      "Epoch 2/30\n",
      "1182/1182 [==============================] - 38s 32ms/step - loss: 0.0791 - accuracy: 0.9768 - val_loss: 0.0465 - val_accuracy: 0.9862\n",
      "Epoch 3/30\n",
      "1182/1182 [==============================] - 31s 27ms/step - loss: 0.0616 - accuracy: 0.9815 - val_loss: 0.0405 - val_accuracy: 0.9881\n",
      "Epoch 4/30\n",
      "1182/1182 [==============================] - 32s 27ms/step - loss: 0.0544 - accuracy: 0.9840 - val_loss: 0.0299 - val_accuracy: 0.9902\n",
      "Epoch 5/30\n",
      "1182/1182 [==============================] - 35s 30ms/step - loss: 0.0464 - accuracy: 0.9854 - val_loss: 0.0312 - val_accuracy: 0.9900\n",
      "Epoch 6/30\n",
      "1182/1182 [==============================] - 32s 27ms/step - loss: 0.0413 - accuracy: 0.9871 - val_loss: 0.0298 - val_accuracy: 0.9910\n",
      "Epoch 7/30\n",
      "1182/1182 [==============================] - 28s 24ms/step - loss: 0.0375 - accuracy: 0.9886 - val_loss: 0.0307 - val_accuracy: 0.9929\n",
      "Epoch 8/30\n",
      "1182/1182 [==============================] - 35s 29ms/step - loss: 0.0344 - accuracy: 0.9888 - val_loss: 0.0324 - val_accuracy: 0.9917\n",
      "Epoch 9/30\n",
      "1182/1182 [==============================] - 34s 29ms/step - loss: 0.0325 - accuracy: 0.9899 - val_loss: 0.0276 - val_accuracy: 0.9919\n",
      "Epoch 10/30\n",
      "1182/1182 [==============================] - 30s 26ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.0327 - val_accuracy: 0.9926\n",
      "Epoch 11/30\n",
      "1182/1182 [==============================] - 28s 23ms/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0356 - val_accuracy: 0.9914\n",
      "Epoch 12/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0280 - accuracy: 0.9910 - val_loss: 0.0361 - val_accuracy: 0.9921\n",
      "Epoch 13/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0249 - accuracy: 0.9920 - val_loss: 0.0287 - val_accuracy: 0.9917\n",
      "Epoch 14/30\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.0258 - val_accuracy: 0.9945\n",
      "Epoch 15/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 0.0285 - val_accuracy: 0.9917\n",
      "Epoch 16/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.0272 - val_accuracy: 0.9924\n",
      "Epoch 17/30\n",
      "1182/1182 [==============================] - 27s 23ms/step - loss: 0.0228 - accuracy: 0.9926 - val_loss: 0.0280 - val_accuracy: 0.9933\n",
      "Epoch 18/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.0348 - val_accuracy: 0.9921\n",
      "Epoch 19/30\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0220 - accuracy: 0.9934 - val_loss: 0.0383 - val_accuracy: 0.9933\n",
      "Epoch 20/30\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0219 - accuracy: 0.9934 - val_loss: 0.0407 - val_accuracy: 0.9893\n",
      "Epoch 21/30\n",
      "1182/1182 [==============================] - 25s 22ms/step - loss: 0.0197 - accuracy: 0.9939 - val_loss: 0.0370 - val_accuracy: 0.9917\n",
      "Epoch 22/30\n",
      "1182/1182 [==============================] - 25s 22ms/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 0.0284 - val_accuracy: 0.9929\n",
      "Epoch 23/30\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 0.0304 - val_accuracy: 0.9933\n",
      "Epoch 24/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0215 - accuracy: 0.9935 - val_loss: 0.0275 - val_accuracy: 0.9929\n",
      "Epoch 25/30\n",
      "1182/1182 [==============================] - 26s 22ms/step - loss: 0.0189 - accuracy: 0.9943 - val_loss: 0.0342 - val_accuracy: 0.9921\n",
      "Epoch 26/30\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.0282 - val_accuracy: 0.9938\n",
      "Epoch 27/30\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0188 - accuracy: 0.9940 - val_loss: 0.0241 - val_accuracy: 0.9945\n",
      "Epoch 28/30\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0257 - val_accuracy: 0.9936\n",
      "Epoch 29/30\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0180 - accuracy: 0.9941 - val_loss: 0.0347 - val_accuracy: 0.9931\n",
      "Epoch 30/30\n",
      "1182/1182 [==============================] - 25s 21ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0430 - val_accuracy: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b3aabd6650>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2triples.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", \n",
    "              metrics = [\"accuracy\"])\n",
    "model2triples.fit(x_train, y_train, epochs = 30, validation_data = (x_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three times the Conv2D and Pooling layers (24, 48, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3triples = Sequential()\n",
    "model3triples.add(Conv2D(24, kernel_size = (3,3), padding = \"Same\", activation = \"relu\", input_shape=(28, 28, 1)))\n",
    "model3triples.add(Conv2D(24, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model3triples.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model3triples.add(Dropout(0.4))\n",
    "\n",
    "model3triples.add(Conv2D(48, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model3triples.add(Conv2D(48, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model3triples.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model3triples.add(Dropout(0.4))\n",
    "\n",
    "model3triples.add(Conv2D(64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model3triples.add(Conv2D(64, kernel_size = (3,3), padding = \"Same\", activation = \"relu\"))\n",
    "model3triples.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model3triples.add(Dropout(0.4))\n",
    "\n",
    "model3triples.add(Flatten())\n",
    "model3triples.add(Dense(256, activation = \"relu\"))\n",
    "model3triples.add(Dropout(0.4))\n",
    "model3triples.add(Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1182/1182 [==============================] - 45s 37ms/step - loss: 0.3637 - accuracy: 0.8811 - val_loss: 0.0933 - val_accuracy: 0.9724\n",
      "Epoch 2/30\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.1118 - accuracy: 0.9673 - val_loss: 0.0580 - val_accuracy: 0.9812\n",
      "Epoch 3/30\n",
      "1182/1182 [==============================] - 45s 38ms/step - loss: 0.0875 - accuracy: 0.9733 - val_loss: 0.0459 - val_accuracy: 0.9860\n",
      "Epoch 4/30\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.0702 - accuracy: 0.9795 - val_loss: 0.0358 - val_accuracy: 0.9881\n",
      "Epoch 5/30\n",
      "1182/1182 [==============================] - 44s 38ms/step - loss: 0.0663 - accuracy: 0.9803 - val_loss: 0.0331 - val_accuracy: 0.9910\n",
      "Epoch 6/30\n",
      "1182/1182 [==============================] - 47s 39ms/step - loss: 0.0607 - accuracy: 0.9816 - val_loss: 0.0379 - val_accuracy: 0.9879\n",
      "Epoch 7/30\n",
      "1182/1182 [==============================] - 46s 39ms/step - loss: 0.0560 - accuracy: 0.9834 - val_loss: 0.0493 - val_accuracy: 0.9862\n",
      "Epoch 8/30\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.0543 - accuracy: 0.9837 - val_loss: 0.0333 - val_accuracy: 0.9900\n",
      "Epoch 9/30\n",
      "1182/1182 [==============================] - 45s 38ms/step - loss: 0.0534 - accuracy: 0.9837 - val_loss: 0.0286 - val_accuracy: 0.9921\n",
      "Epoch 10/30\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.0445 - accuracy: 0.9868 - val_loss: 0.0341 - val_accuracy: 0.9912\n",
      "Epoch 11/30\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.0465 - accuracy: 0.9856 - val_loss: 0.0347 - val_accuracy: 0.9905\n",
      "Epoch 12/30\n",
      "1182/1182 [==============================] - 44s 37ms/step - loss: 0.0441 - accuracy: 0.9869 - val_loss: 0.0343 - val_accuracy: 0.9910\n",
      "Epoch 13/30\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.0453 - accuracy: 0.9871 - val_loss: 0.0395 - val_accuracy: 0.9902\n",
      "Epoch 14/30\n",
      "1182/1182 [==============================] - 44s 38ms/step - loss: 0.0456 - accuracy: 0.9871 - val_loss: 0.0325 - val_accuracy: 0.9910\n",
      "Epoch 15/30\n",
      "1182/1182 [==============================] - 46s 39ms/step - loss: 0.0456 - accuracy: 0.9869 - val_loss: 0.0267 - val_accuracy: 0.9926\n",
      "Epoch 16/30\n",
      "1182/1182 [==============================] - 46s 39ms/step - loss: 0.0425 - accuracy: 0.9874 - val_loss: 0.0388 - val_accuracy: 0.9905\n",
      "Epoch 17/30\n",
      "1182/1182 [==============================] - 43s 36ms/step - loss: 0.0448 - accuracy: 0.9863 - val_loss: 0.0275 - val_accuracy: 0.9929\n",
      "Epoch 18/30\n",
      "1182/1182 [==============================] - 45s 38ms/step - loss: 0.0395 - accuracy: 0.9877 - val_loss: 0.0298 - val_accuracy: 0.9919\n",
      "Epoch 19/30\n",
      "1182/1182 [==============================] - 45s 38ms/step - loss: 0.0387 - accuracy: 0.9886 - val_loss: 0.0331 - val_accuracy: 0.9914\n",
      "Epoch 20/30\n",
      "1182/1182 [==============================] - 43s 37ms/step - loss: 0.0404 - accuracy: 0.9880 - val_loss: 0.0272 - val_accuracy: 0.9924\n",
      "Epoch 21/30\n",
      "1182/1182 [==============================] - 45s 38ms/step - loss: 0.0410 - accuracy: 0.9874 - val_loss: 0.0276 - val_accuracy: 0.9945\n",
      "Epoch 22/30\n",
      "1182/1182 [==============================] - 45s 38ms/step - loss: 0.0393 - accuracy: 0.9883 - val_loss: 0.0284 - val_accuracy: 0.9933\n",
      "Epoch 23/30\n",
      "1182/1182 [==============================] - 45s 38ms/step - loss: 0.0425 - accuracy: 0.9875 - val_loss: 0.0307 - val_accuracy: 0.9919\n",
      "Epoch 24/30\n",
      "1182/1182 [==============================] - 45s 38ms/step - loss: 0.0405 - accuracy: 0.9886 - val_loss: 0.0243 - val_accuracy: 0.9933\n",
      "Epoch 25/30\n",
      "1182/1182 [==============================] - 45s 38ms/step - loss: 0.0406 - accuracy: 0.9887 - val_loss: 0.0295 - val_accuracy: 0.9919\n",
      "Epoch 26/30\n",
      "1182/1182 [==============================] - 42s 36ms/step - loss: 0.0375 - accuracy: 0.9890 - val_loss: 0.0325 - val_accuracy: 0.9933\n",
      "Epoch 27/30\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.0399 - accuracy: 0.9886 - val_loss: 0.0261 - val_accuracy: 0.9929\n",
      "Epoch 28/30\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.0361 - accuracy: 0.9892 - val_loss: 0.0252 - val_accuracy: 0.9933\n",
      "Epoch 29/30\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.0373 - accuracy: 0.9889 - val_loss: 0.0302 - val_accuracy: 0.9926\n",
      "Epoch 30/30\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.0380 - accuracy: 0.9889 - val_loss: 0.0304 - val_accuracy: 0.9931\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b3aad058d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3triples.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", \n",
    "              metrics = [\"accuracy\"])\n",
    "model3triples.fit(x_train, y_train, epochs = 30, validation_data = (x_val, y_val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Using the best combination from above: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9930952380952381"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model3triples.predict(x_val)\n",
    "y_pred_classes = np.argmax(y_pred, axis = 1)\n",
    "y_true = np.argmax(y_val, axis = 1) \n",
    "accuracy_score(y_true, y_pred_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[410,   0,   1,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0, 483,   0,   0,   0,   0,   0,   1,   1,   0],\n",
       "       [  0,   0, 403,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  1,   0,   0, 414,   0,   1,   0,   0,   2,   0],\n",
       "       [  0,   0,   1,   0, 456,   0,   1,   0,   0,   3],\n",
       "       [  0,   0,   0,   1,   0, 367,   3,   0,   1,   0],\n",
       "       [  1,   1,   0,   0,   0,   0, 410,   0,   1,   0],\n",
       "       [  0,   0,   1,   0,   0,   0,   0, 445,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 381,   1],\n",
       "       [  1,   0,   0,   0,   3,   0,   0,   2,   1, 402]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_true, y_pred_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running it on the test set and preparing the submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 4s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# predicting the test set images\n",
    "results = model3triples.predict(test)\n",
    "results = np.argmax(results, axis = 1)\n",
    "results = pd.Series(results, name = \"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the dataframe into a csv file\n",
    "submission = pd.concat([pd.Series(range(1,28001), name = \"ImageId\"), results], axis = 1)\n",
    "submission.to_csv(\"./data/submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a28cd90ab7370ee8139c294f0b491a85c59cce1746513959106cf97723da925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
